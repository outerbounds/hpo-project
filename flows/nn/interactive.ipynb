{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327883ad",
   "metadata": {},
   "source": [
    "## Launching a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpo_client import HyperparameterTuner\n",
    "from utils import load_config\n",
    "\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe611aa2",
   "metadata": {},
   "source": [
    "### (Optional) Iterate on the objective\n",
    "\n",
    "The following piece of code is an example `objective` function. \n",
    "You can use the [`%%writefile` magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-writefile) to write the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile objective_fn_dev.py\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from utils import get_mnist\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    n_classes = 10\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, n_classes))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    batch_size = 128 # trial.suggest_int(\"batch_size\", 32, 128)\n",
    "    n_train_examples = 30\n",
    "    n_valid_examples = 10\n",
    "    epochs = 10\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist(batch_size=batch_size)\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * batch_size >= n_train_examples:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * batch_size >= n_valid_examples:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), n_valid_examples)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e83364",
   "metadata": {},
   "source": [
    "### Run the job\n",
    "\n",
    "Now using, the `HyperparameterTuner` class defined in `hpo_client.py`, we can pass this function we are iterating on. \n",
    "The purpose of this setup is to make it easier to iterate on the contents of the objective in notebook, save it, and run the flow with minimal moving parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c24c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    # objective_function_file=config['objective_function_file'],\n",
    "    objective_function_file='objective_fn_dev.py',\n",
    "    override_study_name=config.get('study_name', None),\n",
    "    optuna_app_name=config['optuna_app_name']\n",
    ")\n",
    "\n",
    "run_id = tuner.run_blocking(\n",
    "    override_compute_pool=config['compute_pool'],\n",
    "    n_trials=config['n_trials'],\n",
    "    trials_per_task=config['trials_per_task']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414c65e",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "After flows complete, the results of the hyperparameter tuning process will be captured in the `results` artifact. \n",
    "If you want to call `utils.load_study` it requires running in a Metaflow task or running the notebook/script from an Outerbounds workstation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47793b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Run\n",
    "from utils import extract_flow_name\n",
    "\n",
    "flow_name = extract_flow_name('flow.py', sanitize=False)\n",
    "run = Run(f\"{flow_name}/{run_id}\")\n",
    "study_df = run.data.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_df = study_df[study_df.where(study_df['state'] == 'PRUNED').state.notna()]\n",
    "completed_df = study_df[study_df.where(study_df['state'] == 'COMPLETE').state.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_df.plot(kind='scatter', x='params_lr', y='value', alpha=0.85, logx=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb2e36",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Either remove the dev file after iteration, or replace the previous objective function definition with this one. \n",
    "How this interacts with branching in GitHub is a matter of preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db12303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A\n",
    "! rm ./objective_fn_dev.py\n",
    "\n",
    "# Option B\n",
    "# ! cp ./objective_fn_dev.py ./objective_fn.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
